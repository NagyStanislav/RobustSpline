% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hello.R
\name{ts_ridge}
\alias{ts_ridge}
\title{(Non-robust) Thin-plate splines regression}
\usage{
ts_ridge(
  X,
  Y,
  tobs,
  m,
  jcv = "all",
  vrs = "C",
  plotCV = FALSE,
  lambda_grid = NULL,
  custfun = NULL
)
}
\arguments{
\item{X}{Matrix of observed values of \code{X} of size 
\code{n}-times-{p}, one row per observation, columns corresponding to the 
positions in the rows of \code{tobs}.}

\item{Y}{Vector of responses of length \code{n}.}

\item{tobs}{Domain locations for the observed points of \code{X}. Matrix
of size \code{p}-times-\code{d}, one row per domain point.}

\item{m}{Order of the thin-plate spline, positive integer.}

\item{jcv}{A numerical indicator of the cross-validation method used to 
select the tuning parameter \code{lambda}. The criteria are always 
based on the residuals (\code{resids}) and hat values (\code{hats}) in
the fitted models. Possible values are:
\itemize{
 \item{"all"}{ All the criteria below are considered.}
 \item{"AIC"}{ Akaike's information criterion given by 
 \code{mean(resids^2)+log(n)*mean(hats)}, where \code{n} is the length of
 both \code{resids} and \code{hats}.}
 \item{"GCV"}{ Leave-one-out cross-validation criterion given by
 \code{mean((resids^2)/((1-hats)^2))}.}
 \item{"GCV(tr)"}{ Modified leave-one-out cross-validation criterion 
 given by \code{mean((resids^2)/((1-mean(hats))^2))}.}
 \item{"BIC"}{ Bayes information criterion given by 
 \code{mean(resids^2)+2*mean(hats)}.}
 \item{"rGCV"}{ A robust version of \code{GCV} where mean is replaced
 by a robust M-estimator of scale of \code{resids/(1-hats)}, see 
 \link[robustbase]{scaleTau2} for details.}
 \item{"rGCV(tr)"}{ Modified version of a \code{rGCV} given by 
 a robust M-estimator of scale of \code{resids/(1-mean(hats))}.}
 \item{"custom"}{ The custom criterion given by function \code{custfun}. 
 Works only if \code{custfun} is part of the input.}
 }}

\item{vrs}{Version of the algorhitm to be used in function \link{ridge}; 
either \code{vrs="C"} for the \code{C++} version, or \code{vrs="R"} for the 
\code{R} version. Both should give (nearly) identical results, see 
\link{IRLS}.}

\item{plotCV}{Indicator of whether a plot of the evaluated cross-validation 
criteria as a function of \code{lambda} should be given.}

\item{lambda_grid}{An optional grid for select \code{lambda} from. By default
this is set to be an exponential of a grid of 51 equidistant values
in the interval from -28 to -1.}

\item{custfun}{A custom function combining the residuals \code{resids} and
the hat values \code{hats}. The result of the function must be numeric, see 
\link{GCV_crit}.}
}
\value{
The output differs depending whether \code{jcv="all"} or 
not. If a specific cross-validation method is selected (that is, 
\code{jcv} is not \code{"all"}), a list is returned:
 \itemize{
 \item{"lambda"}{ The selected tuning parameter \code{lambda} that minimizes
 the chosen cross-validation criterion.}
 \item{"fitted"}{ A vector of \code{n} fitted values using the tuning 
 parameter \code{lambda}.}
 \item{"theta_hat"}{ A numerical matrix of size \code{p+1}-times-\code{1} of 
 estimated regression coefficients from \link{ridge}.}
 \item{"beta_hat"}{ Estimate of the regression function \code{beta0} 
 evaluated at the \code{p} points from \code{tobs}, where \code{X} was
 observed.}
 \item{"alpha_hat"}{ Estimate of \code{alpha0}, a numerical value.}
 \item{"hat_values"}{ Diagonal terms of the (possibly penalized) hat 
 matrix of the form \code{Z*solve(t(Z)*W*Z+n*lambda*H)*t(Z)*W}, 
 where \code{W} is the diagonal weight matrix in the final iteration 
 of \link{IRLS}.}
}
In case when \code{jcv="all"}, all these values are given for each 
cross-validation method considered. For \code{lambda} and \code{alpha_hat},
provides a list of length 6 or 7 (depending on 
whether \code{custfun} is specified); for \code{fitted}, \code{beta_hat},
and \code{hat_values} it gives a matrix with 6 or 7 
columns, each corresponding to one cross-validation method.
}
\description{
Fits a (non-robust) thin-plates spline in a scalar-on-function 
regression problem with discretely observed predictors. The tuning parameter
\code{lambda} is selected using a specified cross-validation criterion.
}
\details{
Function gives a faster (non-iterative) version of the solution
of \link{ts_reg} when \code{type="square"} is used. This corresponds to 
the ridge version of an estimator.
}
\examples{
n = 50      # sample size
p = 10      # dimension of predictors
X = matrix(rnorm(n*p),ncol=p) # design matrix
Y = X[,1]   # response vector
tobs = matrix(sort(runif(p)),ncol=1)

res = ts_ridge(X, Y, tobs, m = 2, jcv = "all", plotCV = TRUE)
}
\references{
Ioannis Kalogridis and Stanislav Nagy. (2023). Robust functional regression 
with discretely sampled predictors. 
\emph{Under review}.
}
\seealso{
\link{ts_reg} for a robust version of this method.
}
