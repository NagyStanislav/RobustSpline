% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hello.R
\name{ts_reg}
\alias{ts_reg}
\title{Robust thin-plate splines regression}
\usage{
ts_reg(
  X,
  Y,
  tobs,
  m,
  type,
  jcv = "all",
  sc = 1,
  vrs = "C",
  plotCV = FALSE,
  lambda_grid = NULL,
  custfun = NULL,
  ...
)
}
\arguments{
\item{X}{Matrix of observed values of \code{X} of size 
\code{n}-times-\code{p}, one row per observation, columns corresponding to the 
positions in the rows of \code{tobs}.}

\item{Y}{Vector of responses of length \code{n}.}

\item{tobs}{Domain locations for the observed points of \code{X}. Matrix
of size \code{p}-times-\code{d}, one row per domain point.}

\item{m}{Order of the thin-plate spline, positive integer.}

\item{type}{The type of the loss function used in the minimization problem.
Accepted are \code{type="absolute"} for the absolute loss \code{rho(t)=|t|}; 
\code{type="square"} for the square loss \code{rho(t)=t^2}; 
\code{type="Huber"} for the Huber loss \code{rho(t)=t^2/2} if 
\code{|t|<tuning} and \code{rho(t)=tuning*(|t|-tuning/2)} otherwise; and 
\code{type="logistic"} for the logistic loss 
\code{rho(t)=2*t + 4*log(1+exp(-t))-4*log(2)}.}

\item{jcv}{A numerical indicator of the cross-validation method used to 
select the tuning parameter \code{lambda}. The criteria are always 
based on the residuals (\code{resids}) and hat values (\code{hats}) in
the fitted models. Possible values are:
\itemize{
 \item{"all"}{ All the criteria below are considered.}
 \item{"AIC"}{ Akaike's information criterion given by 
 \code{mean(resids^2)+log(n)*mean(hats)}, where \code{n} is the length of
 both \code{resids} and \code{hats}.}
 \item{"GCV"}{ Leave-one-out cross-validation criterion given by
 \code{mean((resids^2)/((1-hats)^2))}.}
 \item{"GCV(tr)"}{ Modified leave-one-out cross-validation criterion 
 given by \code{mean((resids^2)/((1-mean(hats))^2))}.}
 \item{"BIC"}{ Bayes information criterion given by 
 \code{mean(resids^2)+2*mean(hats)}.}
 \item{"rGCV"}{ A robust version of \code{GCV} where mean is replaced
 by a robust M-estimator of scale of \code{resids/(1-hats)}, see 
 \link[robustbase]{scaleTau2} for details.}
 \item{"rGCV(tr)"}{ Modified version of a \code{rGCV} given by 
 a robust M-estimator of scale of \code{resids/(1-mean(hats))}.}
 \item{"custom"}{ The custom criterion given by function \code{custfun}. 
 Works only if \code{custfun} is part of the input.}
 }}

\item{sc}{Scale parameter to be used in the IRLS. By default \code{sc=1}, 
that is no scaling is performed.}

\item{vrs}{Version of the algorhitm to be used in function \link{ridge}; 
either \code{vrs="C"} for the \code{C++} version, or \code{vrs="R"} for the 
\code{R} version. Both should give (nearly) identical results, see 
\link{IRLS}.}

\item{plotCV}{Indicator of whether a plot of the evaluated cross-validation 
criteria as a function of \code{lambda} should be given.}

\item{lambda_grid}{An optional grid for select \code{lambda} from. By default
this is set to be an exponential of a grid of 51 equidistant values
in the interval from -28 to -1.}

\item{custfun}{A custom function combining the residuals \code{resids} and
the hat values \code{hats}. The result of the function must be numeric, see 
\link{GCV_crit}.}

\item{...}{A set of additional parameters to be passed to \link{IRLS}.}
}
\value{
The output differs depending whether \code{jcv="all"} or 
not. If a specific cross-validation method is selected (that is, 
\code{jcv} is not \code{"all"}), a list is returned:
 \itemize{
 \item{"lambda"}{ The selected tuning parameter \code{lambda} that minimizes
 the chosen cross-validation criterion.}
 \item{"fitted"}{ A vector of \code{n} fitted values using the tuning 
 parameter \code{lambda}.}
 \item{"theta_hat"}{ A numerical matrix of size \code{p+1}-times-\code{1} of 
 estimated regression coefficients from \link{IRLS}.}
 \item{"beta_hat"}{ Estimate of the regression function \code{beta0} 
 evaluated at the \code{p} points from \code{tobs}, where \code{X} was
 observed.}
 \item{"alpha_hat"}{ Estimate of \code{alpha0}, a numerical value.}
 \item{"hat_values"}{ Diagonal terms of the (possibly penalized) hat 
 matrix of the form \code{Z*solve(t(Z)*W*Z+n*lambda*H)*t(Z)*W}, 
 where \code{W} is the diagonal weight matrix in the final iteration 
 of \link{IRLS}.}
 \item{"weights"}{ The vector of weights given to the observations in the 
 final iteration of \link{IRLS}. For squared loss (\code{type="square"})
 this gives a vector whose all elements are 2.}
 \item{"converged"}{ Indicator whether the \link{IRLS} procedure succefully 
 converged. Takes value 1 if IRLS converged, 0 otherwise.}
}
In case when \code{jcv="all"}, all these values are given for each 
cross-validation method considered. For \code{lambda}, \code{alpha_hat},
and \code{converged} provides a list of length 6 or 7 (depending on 
whether \code{custfun} is specified); for \code{fitted}, \code{beta_hat},
\code{hat_values}, and \code{weights} it gives a matrix with 6 or 7 
columns, each corresponding to one cross-validation method.
}
\description{
Fits a (potentially robust) thin-plates spline in a scalar-on-function 
regression problem with discretely observed predictors. The tuning parameter
\code{lambda} is selected using a specified cross-validation criterion.
}
\examples{
n = 50      # sample size
p = 10      # dimension of predictors
X = matrix(rnorm(n*p),ncol=p) # design matrix
Y = X[,1]   # response vector
tobs = matrix(sort(runif(p)),ncol=1)
type = "absolute" # absolute loss

res = ts_reg(X, Y, tobs, m = 2, type = type, jcv = "all", plotCV = TRUE)
}
\references{
Ioannis Kalogridis and Stanislav Nagy. (2023). Robust functional regression 
with discretely sampled predictors. 
\emph{Under review}.
}
\seealso{
\link{ts_ridge} for a faster (non-robust) version of
this method applied with \code{type="square"}.
}
